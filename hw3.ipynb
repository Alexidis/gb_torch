{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hm3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/ht7UVZ5owM19yq5eu3az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexidis/gb_torch/blob/lesson_3/hm3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uU2qpP6Qr9BZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import datasets as dss\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class housing_ds(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, init_target, transform=None):\n",
        "        self._base_dataset = torch.from_numpy(init_dataset).type(torch.float)\n",
        "        self._base_targets = torch.from_numpy(init_target).type(torch.float)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self._base_dataset[idx]\n",
        "        target = self._base_targets[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "      \n",
        "        return features, target"
      ],
      "metadata": {
        "id": "mvilCHlb1-8U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = activation\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return F.relu(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return F.sigmoid(x)\n",
        "        if self.activation == \"leaky_relu\":\n",
        "            return F.leaky_relu(x)\n",
        "        raise RuntimeError\n",
        "        \n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = Perceptron(input_dim, hidden_dim, 'leaky_relu')\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dp = nn.Dropout(0.15)\n",
        "        self.fc2 = Perceptron(hidden_dim, 1, 'leaky_relu')\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "LQh8jdE77XKd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dss.fetch_california_housing()"
      ],
      "metadata": {
        "id": "oLCrboMB3lG2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size = 0.25, random_state = 13)"
      ],
      "metadata": {
        "id": "hQejJUhL1_GK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = housing_ds(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=150, shuffle=False)"
      ],
      "metadata": {
        "id": "GF06LOeR1_Io"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = housing_ds(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "opqMBOuw1_Lw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForward(8, 8)\n",
        "\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "cjz-jhf-RkZW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "metadata": {
        "id": "_f6uxTxeYjXE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        fets, target = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(fets)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(target)\n",
        "\n",
        "        predict = outputs.data.numpy()\n",
        "        tr_target = target.view(target.shape[0], 1).numpy()\n",
        "        r2 += r2_score(tr_target, predict)\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 30 == 0:\n",
        "            net.eval()\n",
        "\n",
        "            data = list(test_loader)[0]\n",
        "\n",
        "            test_outputs = net(data[0])\n",
        "            test_predict = test_outputs.data.numpy()\n",
        "            te_target = data[1].view(data[1].shape[0], 1)\n",
        "            test_r2 = r2_score(te_target, test_predict)\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'r2: {r2:.3f}. ' \\\n",
        "                  f'Test r2: {test_r2:.3f}')\n",
        "\n",
        "            running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "            net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "id": "eX56CbVc1_RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dad177-fe3a-4279-8cfb-e44ed213f471"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/104]. Loss: 0.040. r2: -3.076. Test r2: -2.865\n",
            "Epoch [1/10]. Step [31/104]. Loss: 0.034. r2: -90.237. Test r2: -3.784\n",
            "Epoch [1/10]. Step [61/104]. Loss: 0.033. r2: -80.962. Test r2: -4.415\n",
            "Epoch [1/10]. Step [91/104]. Loss: 0.026. r2: -59.817. Test r2: -3.730\n",
            "Epoch [2/10]. Step [1/104]. Loss: 0.024. r2: -1.344. Test r2: -2.950\n",
            "Epoch [2/10]. Step [31/104]. Loss: 0.020. r2: -39.488. Test r2: -1.315\n",
            "Epoch [2/10]. Step [61/104]. Loss: 0.019. r2: -34.246. Test r2: -1.229\n",
            "Epoch [2/10]. Step [91/104]. Loss: 0.016. r2: -26.550. Test r2: -1.039\n",
            "Epoch [3/10]. Step [1/104]. Loss: 0.018. r2: -0.621. Test r2: -0.861\n",
            "Epoch [3/10]. Step [31/104]. Loss: 0.015. r2: -22.986. Test r2: -0.754\n",
            "Epoch [3/10]. Step [61/104]. Loss: 0.015. r2: -21.300. Test r2: -0.051\n",
            "Epoch [3/10]. Step [91/104]. Loss: 0.015. r2: -20.841. Test r2: -0.201\n",
            "Epoch [4/10]. Step [1/104]. Loss: 0.015. r2: -0.463. Test r2: -0.245\n",
            "Epoch [4/10]. Step [31/104]. Loss: 0.014. r2: -17.799. Test r2: -0.183\n",
            "Epoch [4/10]. Step [61/104]. Loss: 0.012. r2: -10.381. Test r2: -0.201\n",
            "Epoch [4/10]. Step [91/104]. Loss: 0.012. r2: -11.075. Test r2: -0.387\n",
            "Epoch [5/10]. Step [1/104]. Loss: 0.012. r2: -0.087. Test r2: -0.273\n",
            "Epoch [5/10]. Step [31/104]. Loss: 0.011. r2: -9.315. Test r2: -0.230\n",
            "Epoch [5/10]. Step [61/104]. Loss: 0.012. r2: -8.035. Test r2: -0.130\n",
            "Epoch [5/10]. Step [91/104]. Loss: 0.011. r2: -8.833. Test r2: -0.229\n",
            "Epoch [6/10]. Step [1/104]. Loss: 0.012. r2: -0.137. Test r2: -0.169\n",
            "Epoch [6/10]. Step [31/104]. Loss: 0.011. r2: -8.083. Test r2: -0.563\n",
            "Epoch [6/10]. Step [61/104]. Loss: 0.011. r2: -8.108. Test r2: -0.180\n",
            "Epoch [6/10]. Step [91/104]. Loss: 0.011. r2: -7.345. Test r2: -0.206\n",
            "Epoch [7/10]. Step [1/104]. Loss: 0.012. r2: -0.209. Test r2: -0.274\n",
            "Epoch [7/10]. Step [31/104]. Loss: 0.011. r2: -7.023. Test r2: -0.222\n",
            "Epoch [7/10]. Step [61/104]. Loss: 0.011. r2: -5.971. Test r2: -0.144\n",
            "Epoch [7/10]. Step [91/104]. Loss: 0.011. r2: -5.691. Test r2: -0.184\n",
            "Epoch [8/10]. Step [1/104]. Loss: 0.011. r2: -0.025. Test r2: -0.275\n",
            "Epoch [8/10]. Step [31/104]. Loss: 0.010. r2: -5.165. Test r2: -0.172\n",
            "Epoch [8/10]. Step [61/104]. Loss: 0.010. r2: -4.430. Test r2: -0.097\n",
            "Epoch [8/10]. Step [91/104]. Loss: 0.010. r2: -4.212. Test r2: -0.150\n",
            "Epoch [9/10]. Step [1/104]. Loss: 0.011. r2: 0.034. Test r2: -0.171\n",
            "Epoch [9/10]. Step [31/104]. Loss: 0.010. r2: -4.206. Test r2: -0.105\n",
            "Epoch [9/10]. Step [61/104]. Loss: 0.010. r2: -3.031. Test r2: -0.131\n",
            "Epoch [9/10]. Step [91/104]. Loss: 0.010. r2: -3.741. Test r2: -0.116\n",
            "Epoch [10/10]. Step [1/104]. Loss: 0.011. r2: -0.059. Test r2: -0.159\n",
            "Epoch [10/10]. Step [31/104]. Loss: 0.009. r2: -2.715. Test r2: -0.095\n",
            "Epoch [10/10]. Step [61/104]. Loss: 0.010. r2: -2.513. Test r2: -0.109\n",
            "Epoch [10/10]. Step [91/104]. Loss: 0.009. r2: -2.186. Test r2: -0.142\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "\n"
      ],
      "metadata": {
        "id": "MnX2znRyvfkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По моим наблюдениям с помощью оптимизатора Adam модель быстрее и правильней находит решение.  \n",
        "\n",
        "В целом модель кажется не очень хорошо справляется с задачей регресии"
      ],
      "metadata": {
        "id": "nPP_OaWzCHqU"
      }
    }
  ]
}